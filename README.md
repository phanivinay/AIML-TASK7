# AIML-TASK7
ðŸ§  Task 7: Support Vector Machines (SVM)

This project demonstrates the implementation of Support Vector Machines (SVM) for classification using both Linear and RBF kernels. It includes: dataset loading, preprocessing, model training, hyperparameter tuning, evaluation, and decision boundary visualization.

ðŸš€ Project Overview

This task focuses on understanding how SVMs work for both linearly separable and non-linear datasets. You will learn:

Margin Maximization

Kernel Trick

Hyperparameter Tuning (C, Gamma)

Visualizing Decision Boundaries

Cross-Validation

We use:

Breast Cancer Dataset (built-in from Scikit-learn) for classification

make_circles() synthetic dataset for 2D visualization

ðŸ“¦ Requirements

Install the following Python libraries:

pip install numpy matplotlib scikit-learn
ðŸ“‚ Dataset

This project does not require external downloads. The dataset is loaded directly using:

from sklearn import datasets

Breast Cancer Dataset â†’ For training and testing models

make_circles() â†’ For visualization

ðŸ§ª Features Implemented
âœ” Load & preprocess dataset
âœ” Train SVM (Linear Kernel)
âœ” Train SVM (RBF Kernel)
âœ” Hyperparameter Tuning (GridSearchCV)
âœ” Model evaluation (Accuracy, Classification Report)
âœ” Visualize decision boundaries in 2D
ðŸ“œ Full Code

This README is linked to the Task7.py file containing 100% executable code.

ðŸ“Š Output Includes

Linear SVM Accuracy

RBF SVM Accuracy

Tuned hyperparameters

Confusion matrix & classification reports

Non-linear decision boundary plot

ðŸ§© Key Concepts
ðŸ”¹ Support Vectors

Points closest to the decision boundary.

ðŸ”¹ Margin

Distance between support vectors and hyperplane.

ðŸ”¹ Kernel Trick

Converts low-dimensional data into high-dimensional space for better separation.

ðŸ”¹ Hyperparameters

C â†’ Controls margin softness

gamma â†’ Controls influence of single data point

ðŸ“ˆ Visualization

The 2D plot generated using make_circles() shows how RBF kernel handles non-linear classification.
